
# Simple Chess Transformer Configuration

# Model settings
model:
  vocab_size: 250
  d_model: 256
  num_layers: 4
  num_heads: 4
  max_seq_len: 256
  dropout: 0.1

# Training settings
training:
  learning_rate: 0.001
  batch_size: 8
  max_steps: 10000
  eval_steps: 1000
  save_steps: 2000
  warmup_steps: 500

# Data settings
data:
  max_games: 5000
  min_moves: 10
  max_moves: 100
  stockfish_depth: 10
  stockfish_skill: 15

# Paths
paths:
  data_dir: "data"
  checkpoint_dir: "checkpoints"
  model_save_path: "checkpoints/chess_transformer.pt"
